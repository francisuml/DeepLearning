# Neural Networks Learning Notebook

## Overview
This notebook is designed for learning the fundamentals of neural networks, from basic concepts to practical implementation. It uses the Wisconsin Breast Cancer dataset to build, train, and evaluate a neural network for binary classification. The notebook also includes visualizations, such as a 3D decision boundary plot, to help understand how neural networks make decisions.
Learning Objectives

## Understand the core components of neural networks (layers, weights, biases, activation functions).
Learn about the perceptron, the building block of neural networks.
Explore common activation functions (Sigmoid, ReLU, Tanh) and their roles.
Build and train a neural network using TensorFlow/Keras on real-world data.
Visualize the decision boundary in 3D using PCA-reduced features.
Analyze training performance and draw insights from visualizations.

## Prerequisites

Basic knowledge of Python programming.
Familiarity with machine learning concepts (e.g., classification, train-test split).
Installed dependencies:
Python 3.x
NumPy
Pandas
Matplotlib
Scikit-learn
TensorFlow
Plotly

You can install the required packages using:
pip install numpy pandas matplotlib scikit-learn tensorflow plotly

# Notebook Structure

## Introduction to Neural Networks  

Explanation of neural network components: input layer, hidden layers, output layer, weights, biases, and activation functions.


## The Perceptron  

Implementation of a simple perceptron for binary classification, demonstrating the foundation of neural networks.


## Activation Functions  

Visualization of Sigmoid, ReLU, and Tanh activation functions to understand their behavior and purpose.


## Building a Neural Network  

Using the Wisconsin Breast Cancer dataset to build a neural network with TensorFlow/Keras.
Includes data preprocessing (scaling, splitting) and model training with two hidden layers.


## Evaluating the Model  

Plotting training and validation accuracy/loss curves to assess model performance.
Evaluating the model on a test set.


## 3D Decision Boundary Visualization  

Using PCA to reduce the dataset to 3 dimensions for visualization.
Training a neural network on the reduced data and plotting the decision boundary in 3D.


## Insights and Conclusions  

Key takeaways on perceptron learning, activation functions, neural network architecture, and visualization.
Suggestions for further improvements (e.g., regularization, hyperparameter tuning).



## How to Run

Clone or download the notebook file.
Ensure all dependencies are installed (see Prerequisites).
Open the notebook in a Jupyter environment:jupyter notebook Neural_Network_Learning.ipynb


Run the cells sequentially to follow the learning process.

## Key Insights

Neural networks learn complex patterns through hierarchical feature learning.
Activation functions like ReLU and Sigmoid play a critical role in model performance.
Proper data preprocessing (e.g., scaling) is essential for effective training.
Visualizations, such as 3D decision boundary plots, help understand how neural networks separate classes.
Monitoring training curves helps detect issues


## Author

**Francis Carl Sumile**
* Deep Learning and Machine Learning Enthusiast | Data Science
* github/francisuml

